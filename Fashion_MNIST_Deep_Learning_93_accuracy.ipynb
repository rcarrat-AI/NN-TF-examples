{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Fashion MNIST dataset\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# Split dataset in traning and test subsets\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalization of training and test images\n",
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc7aVvfrwc9_",
        "outputId": "b73a6a30-786c-4909-c673-0dcfa8b37913"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShxPnyh3wDNp",
        "outputId": "cb8ed2ed-a553-4cf0-d439-7a73ac5cdc1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 1.0954 - accuracy: 0.7977\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.8640 - accuracy: 0.8529\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.7668 - accuracy: 0.8683\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6963 - accuracy: 0.8762\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6382 - accuracy: 0.8845\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5967 - accuracy: 0.8887\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5633 - accuracy: 0.8936\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5285 - accuracy: 0.8974\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5011 - accuracy: 0.9011\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4817 - accuracy: 0.9006\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4619 - accuracy: 0.9039\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4422 - accuracy: 0.9055\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4225 - accuracy: 0.9093\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4088 - accuracy: 0.9096\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3934 - accuracy: 0.9131\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3800 - accuracy: 0.9152\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3689 - accuracy: 0.9155\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3612 - accuracy: 0.9172\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3511 - accuracy: 0.9185\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3424 - accuracy: 0.9196\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3361 - accuracy: 0.9211\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3273 - accuracy: 0.9219\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3199 - accuracy: 0.9209\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3136 - accuracy: 0.9241\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3063 - accuracy: 0.9246\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3013 - accuracy: 0.9256\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2950 - accuracy: 0.9258\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2903 - accuracy: 0.9256\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2873 - accuracy: 0.9270\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2860 - accuracy: 0.9268\n"
          ]
        }
      ],
      "source": [
        "# Definimos el modelo de red neuronal\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        # Transformamos un array de 2 dimensiones (78x78) en un array de una dimension 28x28=784 como input_shape\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        # Capa de tipo Dense con 256 neuronas, ReLU y regularización L2\n",
        "        # La regularización L1 y L2 penalizan los pesos de la red para evitar que se vuelvan demasiado grandes\n",
        "        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        # Normalizamos las activaciones de las capa de la red, reduciendo propagación de gradientes\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        # dropout desactiva aleatoriamente algunas neuronas durante el entrenamiento para evitar la dependencia en características específicas.\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        # Output_layer que corresponden con las clases de ropa que tenemos (de 0 a 9) con una función de activación softmax\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Utilizamos un Optimizador Adam con un learning rate de 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Implementamos Early Stop con monitor de tipo accuracy y aumentamos la patience a 10\n",
        "es = EarlyStopping(monitor='accuracy',\n",
        "                   min_delta=0.001,\n",
        "                   verbose=1, \n",
        "                   patience=10)\n",
        "\n",
        "# Entrenamos el modelo durante 30 epochs, utilizando un batch size de 32 e incluyendo Early Stopping\n",
        "history = model.fit(training_images,\n",
        "              training_labels,\n",
        "              epochs=30,\n",
        "              batch_size=32,\n",
        "              callbacks=[es])\n",
        "\n",
        "# Accuracy utilizando los datos de entrenamiento\n",
        "accuracy = history.history['accuracy']\n",
        "print('Training Data accuracy:', accuracy)\n",
        "\n",
        "# Accuracy utilizando los datos de test\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print('\\nTest Data Accuracy:', test_accuracy)"
      ]
    }
  ]
}